---
title: "Análisis de los factores que influyen en la decisión de compra de vivienda a nivel internacional"
author: "Ander Castro & Lucas Martinez"
date: "2025-11-06"
output:
  cleanrmd::html_document_clean:
    theme: kacit
    toc: true
    toc_depth: 5
    toc_float:
      collapsed: false
      smooth_scroll: true
link-citations: true
---

```{r, echo=FALSE, out.width="100%", fig.align="center"}
knitr::include_graphics("./portada.png")
```

# 1. Introducción

La compra de vivienda es uno de los procesos financieros más importantes para los individuos y familias en todo el mundo. Para la mayoría de compradores, esta adquisición se realiza a través de un préstamo hipotecario, por lo que las instituciones financieras evalúan múltiples factores para determinar si un solicitante es elegible para un crédito y bajo qué condiciones.

El mercado inmobiliario global es un sector clave en la economía, moviendo miles de millones de dólares anualmente. La correcta evaluación del perfil financiero del comprador, junto con las características del inmueble, es fundamental tanto para garantizar el acceso a la vivienda como para reducir el riesgo económico de las entidades financieras.

## 1.1 Obtención de los datos

El set de datos fue obtenido de la plataforma Kaggle y contiene información global sobre compras de vivienda y decisiones de aprobación hipotecaria. Incluye 200,000 registros (muestras) con 25 variables relacionadas tanto con la propiedad como con el comprador y su historial financiero.

El objetivo principal de este estudio es realizar un análisis estadístico para comprender qué factores influyen en la aprobación o rechazo de un préstamo hipotecario. Asimismo, se buscará identificar qué características del comprador y de la propiedad tienen mayor peso en la decisión final y desarrollar modelos predictivos que permitan anticipar el resultado de aprobación crediticia.

## 1.2 Metodología

A lo largo de este trabajo, se pretenden analizar las siguientes preguntas:

- *¿Qué variables explican mejor el precio de una vivienda?*
  - ¿Influyen el país, tipo de propiedad, tamaño y número de crímenes reportados?
  - ¿Qué relación existe entre el precio y variables como el salario del comprador o el pago previo a la hipotéca?
  
- *¿Qué factores determinan la decisión de compra (variable decision)?*
  - ¿Qué peso tienen variables como el ratio EMI/income, el nivel de satisfacción, el número de habitaciones o la cantidad de propietarios anteriores?
  - ¿Se puede predecir la decisión de compra con un modelo de clasificación?
  
- *¿Existen diferencias significativas entre países o ciudades en cuanto a precios y decisiones de compra?*
  - ¿Qué países tienen precios más altos en promedio? ¡Y más bajos?

- *¿Qué factores recogen la mayoría de la información del dataset?*
  - ¿Es posible simplificar el conjunto de variables en un conjunto más pequeño de componentes principales que capture la mayor parte de la varianza?
  - ¿Cuántos componentes necesitaríamos para capturar el 80% de la varianza?
  
- *¿Qué insights se pueden extraer sobre el perfil del comprador?*
  - ¿Qué relación hay entre salario, gastos mensuales, préstamo y decisión de compra?
  - ¿Influyen los aspectos legales (legal_cases_on_property) o de seguridad (crime_cases_reported)?

El análisis se llevará a cabo de la siguiente manera:

1. Importación de librerías y datos  
2. Resumen estadístico general 
3. Visualización de datos
4. Contraste de hipótesis y estadística inferencial
5. PCA: Análisis de Componentes Principales  
    - Varianza explicada  
    - Componentes principales
6. Modelos de Machine Learning para la decisión de compra
    - Regresión Logística
    - Random Forest
7. Interpretación de resultados
8. Conclusiones y limitaciones
9. Bibliografía

## 1.3 Variables del dataset

El conjunto de datos **Global House Purchase Decision Dataset** contiene información detallada sobre propiedades residenciales, características del entorno y perfil financiero de los compradores. En total, incluye **200.000 observaciones** y **25 variables**, que permiten analizar los factores que influyen en la decisión de compra.

A continuación, se describen las variables incluidas en el dataset:

- `property_id`: Identificador único de cada propiedad.
- `country`: País donde se encuentra la propiedad.  
- `city`: Ciudad en la que está ubicada la vivienda.  
- `property_type`: Tipo de propiedad.
- `furnishing_status`: Nivel de amueblado del inmueble.  
- `property_size_sqft`: Tamaño total de la propiedad en pies cuadrados.
- `price`: Precio de la vivienda en dólares estadounidenses (USD).  
- `constructed_year`: Año en el que se construyó la propiedad.
- `previous_owners`: Número de propietarios previos.
- `rooms`: Número de dormitorios de la vivienda.  
- `bathrooms`: Número de baños de la vivienda.
- `garage`: Indica si la propiedad dispone de garaje propio (variable binaria: 1 = sí, 0 = no).
- `garden`: Indica si la propiedad cuenta con jardín o espacio exterior privado (variable binaria: 1 = sí, 0 = no).
- `crime_cases_reported`: Número de crímenes reportados en la zona (indicador de seguridad).
- `legal_cases_on_property`: Número de casos legales asociados a la propiedad.
- `customer_salary`: Salario del comprador (en USD).  
- `loan_amount`: Monto solicitado del préstamo hipotecario.  
- `loan_tenure_years`: Duración del préstamo en años.  
- `monthly_expenses`: Gastos mensuales promedio del comprador.
- `down_payment`: Cantidad inicial que el comprador aporta en efectivo para la compra, antes del préstamo hipotecario.
- `emi_to_income_ratio`: Relación entre la cuota mensual del préstamo (EMI, Equated Monthly Installment) y el ingreso mensual del comprador.
- `satisfaction_score`: Puntuación de satisfacción subjetiva del comprador (escala 1–10).
- `neighbourhood_rating`: Puntuación de la zona o vecindario (escala 1-10).
- `connectivity_score`: Medida de accesibilidad y transporte de la propiedad (escala 1-10).
- `decision`: Variable objetivo binaria: *1 = Compra aprobada / 0 = No compra*.

# 2. Análisis exploratorio de los datos

## 2.1 Importar datos y librerías

```{r setup, message=FALSE, warning=FALSE}
library(dplyr)
library(ggplot2)
library(tidyr)
library(corrplot)
library(scales)
library(broom)
library(car)
library(caret)
library(xgboost)
library(glmnet)
library(pROC)

data <- read.csv('./global_house_purchase_dataset.csv')
glimpse(data)
```

- ¿Hay valores faltantes? ¿Y duplicados?
```{r}
sum(is.na(data))
sum(duplicated(data))
```

## 2.2 Resumen estadístico general

```{r}
data %>%
  select_if(is.numeric) %>%
  summary()
```
```{r}
sapply(data %>% select(where(is.character)), n_distinct)
```

## 2.3 Visualización de datos

### **Distribución de la variable `decision`**

```{r}
data %>%
  count(decision) %>%
  mutate(pct = n/sum(n)*100,
         decision = factor(decision, labels = c("No compra", "Compra"))) %>%
  ggplot(aes(x = decision, y = pct, fill = decision)) +
  geom_col() +
  geom_text(aes(label = sprintf("%.2f%%", pct)), 
            vjust = 1.5, color = "black", size = 4) +
  labs(title = "Distribución de la decisión de compra",
       x = "Decisión", y = "%") +
  scale_fill_manual(values = c("#F8766D", "#00BA38")) +
  theme_minimal() +
  theme(legend.position = "none")
```

El gráfico representa la distribución porcentual de la variable decision, que indica si un cliente decide o no comprar una vivienda. Se observa un desequilibrio marcado entre ambas categorías: el 76.97% de los individuos no realiza la compra, mientras que solo el 23.03% decide concretarla.

Esta distribución desequilibrada es un aspecto importante a considerar, ya que puede influir en el rendimiento de los modelos predictivos.

### **Distribución del precio**

```{r}
ggplot(data, aes(x = price)) +
  geom_histogram(fill = "#69b3a2", color = "white", bins = 40) +
  scale_x_continuous(labels = comma) +
  labs(title = "Distribución del precio de las viviendas",
  x = "Precio (USD)", y = "Frecuencia") +
  theme_minimal()
```

El histograma muestra la distribución del precio de las viviendas en dólares estadounidenses (USD). Se observa una distribución asimétrica a la derecha, parecida a una distribución gamma, lo que indica que la mayoría de los inmuebles se concentran en los rangos de precios más bajos, mientras que un número reducido de propiedades presenta precios considerablemente más altos.

La mayor frecuencia de viviendas se sitúa aproximadamente entre los 500,000 y 1,000,000 USD, reflejando que este rango constituye el segmento más representativo del mercado analizado. A partir de valores superiores a los 2 millones de dólares, la frecuencia disminuye progresivamente, mostrando la presencia de propiedades de lujo que elevan la cola derecha de la distribución.

A continuación, aplicaremos una transformación logarítmica al precio con el objetivo de aproximar su distribución a una normal.

```{r}
data <- data %>% mutate(log_price = log(price))

ggplot(data, aes(x = log_price)) +
  geom_histogram(fill = "#69b3a2", color = "white", bins = 40) +
  scale_x_continuous() +
  labs(title = "Distribución del logaritmo del precio de las viviendas",
  x = "Precio (USD)", y = "Frecuencia") +
  theme_minimal()
```

Tras aplicar la transformación logarítmica al precio de las viviendas, se observa que la distribución se aproxima más a una distribución normal, corrigiendo la fuerte asimetría a la derecha presente en los valores originales.

### **Distribución del precio por país y por tipo de propiedad**

```{r}
# Boxplot de precios por país
data %>%
  ggplot(aes(x = country, y = price)) +
  geom_boxplot(fill = "#56B4E9", outlier.alpha = 0.2) +
  coord_flip() +
  scale_y_continuous(labels = comma) +
  labs(title = "Distribución del precio por país (Top 10)",
       x = "País", y = "Precio (USD)") +
  theme_minimal()
```

En este gráfico se aprecia que Singapur, Emiratos Árabes Unidos (UAE), Japón y Estados Unidos presentan los precios medianos más altos, así como una mayor dispersión, lo que refleja mercados con viviendas de alto valor y mayor desigualdad de precios. En contraste, países como Brasil, India y Sudáfrica muestran precios sustancialmente más bajos y con menor variabilidad, indicando mercados más accesibles y homogéneos.

```{r}
# Boxplot de precios por tipo de propiedad

data %>%
  ggplot(aes(x = property_type, y = price)) +
  geom_boxplot(fill = "#56B4E9", outlier.alpha = 0.2) +
  scale_y_continuous(labels = comma) +
  coord_flip() +
  labs(title = "Distribución del precio por tipo de propiedad (Top 10)",
       x = "Propiedad", y = "Precio (USD)") +
  theme_minimal()
```

Por otro lado, el boxplot por tipo de propiedad evidencia que no hay diferencias estructurales dentro de cada mercado. Si bien es cierto que hay propiedades muy caras (outliers) en todos los tipos de propiedades, las distribuciones centrales son bastante similares, sin diferencias estructurales marcadas entre categorías.

### **Relaciones entre variables numéricas**

```{r}
# Seleccionar variables numéricas relevantes

num_vars <- data %>%
  select_if(is.numeric) %>%
  select(-property_id)

# Matriz de correlación

corr_matrix <- cor(num_vars)

corrplot(corr_matrix, method = "color", type = "upper", tl.col = "black", order = "hclust")
```

El análisis de las relaciones entre las variables numéricas revela patrones coherentes con el comportamiento esperado en un contexto inmobiliario. 

En primer lugar, se observa una correlación positiva entre el precio de la vivienda y el tamaño del inmueble (`property_size_sqft`), lo cual es lógico, ya que las propiedades de mayor superficie tienden a tener precios más altos.

Asimismo, variables como el salario del comprador (`customer_salary`), la cantidad inicial que el comprador aporta (`down_payment`) y el monto del préstamo (`loan_amount`) muestran también una relación directa con el precio, reflejando que los compradores con mayor capacidad económica tienden a adquirir viviendas más costosas.

En cuanto a correlaciones negativas, vemos una relación lógica entre `customer_salary` y `emi_to_income_ratio`: cuanto mayor es el salario del comprador, menor es la proporción que representa la cuota mensual del préstamo respecto a sus ingresos. Esto es coherente, ya que un ingreso alto diluye el peso relativo de la cuota hipotecaria, mejorando la capacidad de pago.

Además, existe una correlación negativa interesante entre `legal_cases_on_property` y `decision`. Esto significa que, a medida que aumentan los casos legales asociados a una propiedad, disminuye la probabilidad de que la decisión final sea positiva (compra aprobada).

### **Relaciones bivariantes**

```{r}
# Salario vs Decisión de compra
data %>%
  mutate(decision = factor(decision, labels = c("No compra", "Compra"))) %>%
  ggplot(aes(x = decision, y = customer_salary, fill = decision)) +
  geom_boxplot(outlier.alpha = 0.2) +
  scale_fill_manual(values = c("#F8766D", "#00BA38")) +
  labs(title = "Salario según decisión de compra",
  x = "Decisión", y = "Salario del cliente") +
  theme_minimal() +
  theme(legend.position = "none")
```

```{r}
# Número de crímenes reportados vs Precio medio
data %>%
  group_by(crime_cases_reported) %>%
  summarise(mean_price = mean(price, na.rm = TRUE)) %>%
  ggplot(aes(x = factor(crime_cases_reported), y = mean_price)) +
  geom_col(fill = "#56B4E9") +
  scale_y_continuous(labels = comma) +
  labs(title = "Precio medio según el número de crímenes reportados",
  x = "Número de crímenes", y = "Precio medio (USD)") +
  theme_minimal()
```

El análisis de las relaciones bivariantes permite identificar cómo ciertas variables influyen directamente en la decisión de compra y en el precio de la vivienda.  

En primer lugar, se observa que el salario del cliente (`customer_salary`) presenta una relación positiva con la decisión de compra.

Por otra parte, la relación entre el número de crímenes reportados (`crime_cases_reported`) y el precio medio de las viviendas muestra una tendencia inversa: los precios disminuyen a medida que aumenta la incidencia delictiva.

### **Decisión de compra por país**

```{r}
# ¿Qué porcentaje de personas toma la decisión de comprar una vivienda en cada país?
data %>%
  group_by(country) %>%
  summarise(pct_purchase = mean(decision) * 100) %>%
  arrange(desc(pct_purchase)) %>%
  slice_head(n = 10) %>%
  ggplot(aes(x = reorder(country, pct_purchase), y = pct_purchase)) +
  geom_col(fill = "#009E73") +
  geom_text(aes(label = sprintf("%.2f%%", pct_purchase)), 
            hjust = 1.2, color = "white", size = 4) +
  coord_flip() +
  labs(title = "Porcentaje de decisión de compra por país (Top 10)",
  x = "País", y = "% de compras") +
  theme_minimal()
```

El análisis de la decisión de compra por país revela diferencias significativas en el comportamiento de los compradores según su ubicación geográfica.

Se observa que algunos países presentan una mayor proporción de decisiones de compra positivas, lo que puede estar relacionado con factores como la estabilidad económica, el nivel de ingresos promedio o las características del mercado inmobiliario local.

# 3. Contraste de hipótesis y estadística inferencial

En esta sección se pretende verificar estadísticamente algunas de las relaciones sugeridas en el análisis exploratorio previo. Para ello, se formulan hipótesis estadísticas y se aplican pruebas de contraste adecuadas según el tipo de variable y la distribución observada.

## 3.1 Diferencias de precio entre países

Hipótesis:

- H0: El precio medio es igual entre los países.
- H1: Al menos un país presenta un precio medio distinto.

```{r}
# Test de normalidad
shapiro.test(sample(data$log_price, 5000))
```

El test de Shapiro–Wilk, aplicado a una muestra aleatoria de la variable `log_price`, muestra un p-value < 2.2e-16, lo que sugiere que la variable transformada no sigue una distribución normal perfecta. No obstante, dado el gran tamaño muestral, el ANOVA resulta suficientemente robusto frente a desviaciones de normalidad, por lo que la ligera falta de ajuste no compromete la validez del análisis.

A continuación, se realiza la prueba de Levene para ver si las varianzas entre países son homogéneas o no, y esto nos indicará si podemos utilizar el test paramétrico de ANOVA o, en caso contrario, el de Kruskal-Wallis.

```{r}
# Test de homogeneidad de varianzas
leveneTest(log_price ~ factor(country), data = data)
```

El resultado (p = 0.126) sugiere que no existe evidencia suficiente para rechazar la hipótesis nula de igualdad de varianzas, cumpliéndose así el supuesto de homocedasticidad. Por ello, se aplicó un ANOVA clásico para comparar el precio medio entre países usando la variable transformada.

```{r}
# ANOVA
anova_country <- aov(log_price ~ factor(country), data = data)
summary(anova_country)
```

El ANOVA realizado sobre el precio de la vivienda en su escala logarítmica revela diferencias estadísticamente significativas entre países. El modelo muestra un p-value < 2e-16, lo que indica que la variación del precio medio de las viviendas difiere de forma sustancial según el país.

Ahora llevaremos a cabo el test de Tukey para ver qué países difieren entre sí en el precio medio. Este test incluye una corrección automática del error familiar (FWER), garantizando que la probabilidad de obtener falsos positivos se mantenga controlada al realizar múltiples comparaciones simultáneas.

```{r}
# Post-hoc Tukey
tukey <- TukeyHSD(anova_country)
tukey
sum(tukey[["factor(country)"]][, "p adj"]>0.05)
```

El test post-hoc de Tukey mostró diferencias significativas entre todos los pares de países (p-value < 0.05), confirmando que el país de localización es un factor determinante en el precio de la vivienda.

## 3.2 Diferencia de precio entre casas con y sin jardín

Hipótesis:

- H0: El precio medio de las casas con jardín es igual al precio medio de las casas sin jardín.
- H1: El precio medio es diferente.

```{r}
t_test <- data%>%
  mutate(garden = factor(garden)) %>%
  select(price, garden)

shapiro.test(sample(t_test$price[t_test$garden == 0], 5000))
shapiro.test(sample(t_test$price[t_test$garden == 1], 5000))

wilcox <- wilcox.test(price ~ garden, data = data)
wilcox
```

El test de Shapiro-Wilk aplicado a los precios en los grupos con y sin jardín presentó p-values menores a 2.2e-16, lo que indica que en ambos casos la distribución del precio se desvía significativamente de la normalidad. Por esta razón, se utilizó el test no paramétrico de Wilcoxon para comparar los precios entre los dos grupos. El resultado del test (p = 0.9945) muestra que no existe evidencia estadísticamente significativa para afirmar que el precio de las propiedades difiera entre viviendas con jardín y viviendas sin jardín. En otras palabras, la presencia de jardín no parece estar asociada con diferencias en el nivel de precios dentro de este conjunto de datos.

## 3.3 Dependencia entre el tipo de propiedad y garaje

Hipótesis:

- H0: El tipo de propiedad es independiente de si tiene garaje.
- H1: Las variables son dependientes (existe una asociación).

```{r}
tabla_contingencia <- table(data$property_type, data$garage)
tabla_contingencia

# Test de Chi-cuadrado
chi_resultado <- chisq.test(tabla_contingencia)
chi_resultado
```

Se realizó un test de Chi-cuadrado para evaluar la relación entre el tipo de propiedad y la presencia de garaje. El resultado obtenido (p = 0.036) indica que existe una diferencia estadísticamente significativa entre ambos factores, ya que el p-value es menor que 0.05. Esto implica que la disponibilidad de garaje no es independiente del tipo de vivienda: algunos tipos de propiedad presentan mayor probabilidad de contar con garaje que otros.

# 4. PCA: Análisis de Componentes Principales

El análisis de componentes principales (PCA) es clave para identificar los factores que explican la mayor parte de la variabilidad en nuestro conjunto de datos.

```{r}
# PCA no admite factores ni variables categóricas
pca_data <- data %>%
  select(property_size_sqft, price, log_price,constructed_year,
         previous_owners, rooms, bathrooms, garage, garden,
         crime_cases_reported, legal_cases_on_property,
         customer_salary, loan_amount, loan_tenure_years,
         monthly_expenses, down_payment, emi_to_income_ratio,
         satisfaction_score, neighbourhood_rating,
         connectivity_score)

pca_result <- prcomp(pca_data, scale. = TRUE)
summary(pca_result)
```

## 4.1 Varianza explicada los componentes

```{r}
varianza_explicada <- pca_result$sdev^2 /sum(pca_result$sdev^2)
varianza_acumulada <- cumsum(varianza_explicada)

df_varianza <- data.frame(
  Componente = 1:length(varianza_acumulada),
  Varianza_Acumulada = varianza_acumulada
)

ggplot(df_varianza, aes(x = Componente, y = Varianza_Acumulada)) +
  geom_line(color = "#0072B2", linewidth = 1) +
  geom_point(color = "#0072B2", size = 2) +
  geom_hline(yintercept = 0.80, linetype = "dashed", color = "red") +
  theme_minimal() +
  labs(title = "Varianza explicada acumulada",
       x = "Número de Componentes",
       y = "Varianza Acumulada") +
  scale_x_continuous(breaks = df_varianza$Componente)
```

Los resultados indican que el primer componente principal (PC1) captura una porción significativa de la varianza total, alrededor del 20%. Además, los primeros diez componentes en conjunto explican cerca del 70–75% de la variabilidad del conjunto de datos.

## 4.2 ¿Qué información nos dan las dos primeras componentes?

```{r}
# Extraer scores de las dos primeras componentes
scores <- as.data.frame(pca_result$x[,1:2])
scores$country <- data$country

ggplot() +
  geom_point(data = scores, aes(x = PC1, y = PC2, color =
                                  country), alpha = 0.6) +
  theme_minimal() +
  labs(title = "Primeras dos componentes del PCA",
       x = "PC1",
       y = "PC2",
       color = "País")
```

Se representaron gráficamente las dos primeras componentes principales (PC1 y PC2) obtenidas del análisis PCA con el objetivo de visualizar cómo se distribuyen los países en el nuevo espacio de menor dimensión. En este gráfico, cada punto corresponde a una vivienda y los colores indican el país al que pertenece. En este caso, no se aprecia una separación fuerte entre países (quizás Singapur sí difiera del resto) lo que sugiere que las características cuantitativas consideradas presentan estructuras similares entre regiones, o que las diferencias entre países quedan capturadas en componentes posteriores con menor varianza explicada. En otras palabras, el país por sí solo no parece ser el factor principal de variación en las características numéricas de los inmuebles dentro del conjunto de datos.

## 4.3 Variables que más contribuyen a PC1 y PC2

```{r}
# Qué variables contribuyen a PC1 y PC2
loadings <- as.data.frame(pca_result$rotation[,1:2])
loadings$variable <- rownames(loadings)

# Contribución para PC1
PC1_contrib_df <- loadings %>%
  select(PC1) %>%
  arrange(desc(PC1))

# Contribución para PC2
PC2_contrib_df <- loadings %>%
  select(PC2) %>%
  arrange(desc(PC2))

head(PC1_contrib_df, 5)
head(PC2_contrib_df, 5)
```

PC1 está fuertemente asociado con el nivel económico y el tamaño de la propiedad. Las variables financieras (precio, cantidad de préstamo, pago inicial) y el tamaño del inmueble tienen cargas altas y positivas, lo que indica que este componente captura principalmente un gradiente de propiedades de mayor costo y mayor superficie frente a propiedades más económicas y pequeñas.

PC2 está dominado casi exclusivamente por la estructura interna del inmueble (número de habitaciones y baños). Estos dos atributos se mueven prácticamente de forma conjunta y definen la configuración habitacional del inmueble, independientemente del precio total.

# 5. Machine Learning: Modelos para predecir `decision`

## 5.1 Regresión logística con Lasso y Cross-Validation

```{r}
data$decision <- as.factor(data$decision)
data$country <- as.factor(data$country)

train_index <- createDataPartition(data$decision, p = 0.8, list = FALSE)

train_data <- data[train_index, ]
test_data <- data[-train_index, ]

# Comprobar proporciones
prop.table(table(train_data$decision))
prop.table(table(test_data$decision))
```

Primero se convirtió la variable decision y country en factores, ya que ambas representan categorías y no valores numéricos continuos. A continuación, se realizó una partición del conjunto de datos en dos subconjuntos: uno de entrenamiento (80% de las observaciones) y otro de prueba (20% restante). La partición se llevó a cabo de manera estratificada utilizando la función createDataPartition, lo que garantiza que la proporción de clases en la variable decision se mantenga similar en ambos conjuntos. El conjunto de entrenamiento (train_data) se empleará para ajustar los modelos de clasificación, mientras que el conjunto de prueba (test_data) se utilizará posteriormente para evaluar su rendimiento y capacidad de generalización. Esto permite evitar el sobreajuste y obtener una estimación más realista del desempeño del modelo sobre datos no vistos durante el entrenamiento.

```{r}
# Definir la fórmula del modelo
formula <- decision ~ log_price + country + satisfaction_score + bathrooms + rooms + previous_owners

x_train <- model.matrix(formula, data = train_data)[, -1]
y_train <- train_data$decision

x_test <- model.matrix(formula, data = test_data)[, -1]
y_test <- test_data$decision
```

En este bloque de código se define primero la fórmula del modelo, indicando que la variable respuesta será decision, mientras que las variables predictoras seleccionadas son log_price, country, satisfaction_score, bathrooms, rooms y previous_owners. A continuación, se utiliza la función model.matrix() para transformar esta fórmula en matrices numéricas que puedan ser utilizadas por modelos como Lasso o cualquier algoritmo de machine learning que requiera datos puramente numéricos. Esta función convierte automáticamente las variables categóricas, como country, en variables dummy (codificación one-hot), y posteriormente se elimina la primera columna para evitar problemas de multicolinealidad. De este modo, x_train y x_test contienen únicamente predictores numéricos, mientras que y_train y y_test guardan la variable objetivo en formato factor.

```{r, eval=FALSE}
lasso_model_cv <- cv.glmnet(
  x_train,
  y_train,
  alpha = 1,
  family = "binomial",
  type.measure = "auc"
)
```
```{r, include=FALSE}
lasso_model_cv <- readRDS("model_lasso_cv.rds")
```

En este paso se entrena un modelo Lasso aplicado a regresión logística utilizando la función cv.glmnet(). El parámetro alpha = 1 especifica que se emplea la penalización Lasso, cuya característica principal es la selección automática de variables, ya que fuerza a algunos coeficientes a volverse exactamente cero, eliminando predictores poco relevantes. Se indica además family = "binomial" porque la variable respuesta decision es categórica binaria, por lo que el modelo ajusta probabilidades mediante una función logística. La opción type.measure = "auc" hace que el proceso de validación cruzada seleccione el valor óptimo del parámetro de regularización λ maximizando el área bajo la curva ROC, favoreciendo un modelo con buen poder discriminativo. De esta manera, el modelo resultante equilibra adecuadamente complejidad y rendimiento, reteniendo únicamente las variables más informativas para la predicción de la decisión de compra.

```{r message=FALSE, warning=FALSE}
# Extraer el valor óptimo de Lambda (el que maximiza el AUC)
lambda_min <- lasso_model_cv$lambda.min

predictions_prob <- predict(lasso_model_cv, s = lambda_min,
                            newx = x_test, type = "response")[,1]

# Calcular la curva ROC y el AUC
roc_curve <- roc(response = y_test, predictor = predictions_prob)
auc_value <- auc(roc_curve)

coef_matrix <- coef(lasso_model_cv, s = lambda_min)

coef_plot <- data.frame(
  term = coef_matrix@Dimnames[[1]][coef_matrix@i + 1],
  estimate = coef_matrix@x)

# Filtrar el intercept y los coeficientes que Lasso hizo 0
coef_plot_filtered <- coef_plot %>%
  filter(term != "(Intercept)" & estimate != 0) %>%
  mutate(term = reorder(term, estimate))
```

Una vez entrenado el modelo Lasso mediante validación cruzada, se extrae el valor óptimo del parámetro de regularización λ (lambda.min), que corresponde al modelo con mayor área bajo la curva ROC (AUC). Utilizando este valor, se generan predicciones de probabilidad para los datos de test. Dichas probabilidades se evalúan mediante la curva ROC, obteniendo el valor del AUC, que resume la capacidad del modelo para discriminar entre compradores y no compradores.

A continuación, se extraen los coeficientes del modelo en el punto lambda.min. Debido a la penalización Lasso, algunos coeficientes se reducen a cero y, por tanto, esas variables se eliminan del modelo. Solo se conservan aquellas que presentan una contribución relevante a la predicción. Ahora se creará un gráfico que muestra únicamente los coeficientes distintos de cero, permitiendo visualizar el sentido y magnitud del efecto de cada variable. Coeficientes positivos indican que un aumento en dicha variable incrementa la probabilidad de compra, mientras que coeficientes negativos la reducen. Este enfoque facilita interpretar cuáles factores son más determinantes en la decisión y refuerza la capacidad del Lasso para realizar selección de variables de manera directa y eficiente.

```{r message=FALSE, warning=FALSE}
ggplot(coef_plot_filtered, aes(x = term, y = estimate)) +
  geom_point(aes(color = estimate > 0), size = 3) +
  geom_segment(aes(x = term, xend = term, y = 0, yend = estimate)) +
  coord_flip() +
  theme_minimal() +
  scale_color_discrete(name = "Efecto", labels = c("Negativo", "Positivo")) +
  labs(title = "Efecto de las variables seleccionadas por Lasso",
       x = "Variables", 
       y = "Coeficiente (Log-Odds)")
```

El modelo de regresión logística muestra que la decisión de compra está influida principalmente por el precio de la vivienda (en su escala logarítmica), el país donde se ubica el inmueble y el nivel de satisfacción del comprador. En particular, se observa que el coeficiente de log_price es negativo y altamente significativo (p-value < 2e-16), lo que indica que, a medida que el precio aumenta, la probabilidad de que el comprador decida adquirir la vivienda disminuye. Este resultado sugiere que la capacidad económica es un factor limitante importante en la decisión.

La variable satisfaction_score presenta un efecto positivo y muy significativo, implicando que un mayor nivel de satisfacción incrementa considerablemente la probabilidad de compra. Este resultado destaca el papel de la percepción personal y la valoración emocional del inmueble en la toma de decisiones, además de los factores económicos.

En cuanto al país de residencia, se identifican diferencias significativas entre mercados. Los compradores en Brasil, India, Sudáfrica, Singapur, Emiratos Árabes Unidos y Estados Unidos presentan probabilidades de compra significativamente menores en comparación con el país de referencia (Australia).

Por el contrario, variables relacionadas con las características físicas del inmueble —como el número de baños (`bathrooms`), de habitaciones (`rooms`) o de propietarios anteriores (`previous_owners`)— no muestran efectos estadísticamente significativos cuando se controlan las demás variables del modelo.

## 5.2 Random Forest con GridSearch y Cross-Validation

Vamos a seleccionar las variables relevantes y a preparar los datos de igual manera que para la regresión logística.

```{r message=FALSE, warning=FALSE}
ml_data <- data %>%
  select(decision, log_price, country, satisfaction_score,
         neighbourhood_rating, connectivity_score,
         emi_to_income_ratio, bathrooms, rooms,
         previous_owners)

ml_data$decision <- as.factor(ml_data$decision)
ml_data$country <- as.factor(ml_data$country)

# Dividir en train y test
train_index <- createDataPartition(ml_data$decision, p = 0.8, list = FALSE)
train <- ml_data[train_index, ]
test  <- ml_data[-train_index, ]

# Comprobar proporciones
prop.table(table(train$decision))
prop.table(table(test$decision))
```
A continuación, creamos y entrenamos nuestro modelo.

```{r message=FALSE, warning=FALSE}
train$decision <- factor(train$decision, levels = c(0,1), labels = c("No","Si"))
test$decision  <- factor(test$decision,  levels = c(0,1), labels = c("No","Si"))

dummies <- dummyVars(decision ~ ., data = train)
train_x <- predict(dummies, newdata = train)
test_x  <- predict(dummies, newdata = test)

train_y <- ifelse(train$decision == "Si", 1, 0)
test_y  <- ifelse(test$decision == "Si", 1, 0)

dtrain <- xgb.DMatrix(data = as.matrix(train_x), label = train_y)
dtest  <- xgb.DMatrix(data = as.matrix(test_x), label = test_y)
```
```{r eval=FALSE, message=FALSE, warning=FALSE}
ctrl <- trainControl(
  method = "cv",
  number = 5,
  classProbs = TRUE,
  summaryFunction = twoClassSummary,
  verboseIter = TRUE
)

grid <- expand.grid(
  nrounds = seq(100, 500, by = 100),
  max_depth = c(3, 5, 7),
  eta = c(0.01, 0.05, 0.1),
  gamma = 0,
  colsample_bytree = c(0.6, 0.8),
  min_child_weight = c(1, 3),
  subsample = c(0.7, 1)
)

xgb_model <- train(
  x = train_x,
  y = train$decision,
  method = "xgbTree",
  metric = "ROC",
  trControl = ctrl,
  tuneGrid = grid
)
```
```{r, include=FALSE}
xgb_model <- readRDS("xgb_model_final.rds")
```

En este bloque se define y entrena un modelo de clasificación basado en XGBoost utilizando validación cruzada y ajuste de hiperparámetros. La función trainControl() establece una validación cruzada de 5 particiones, calculando probabilidades de clase y empleando el AUC como métrica principal mediante summaryFunction = twoClassSummary, lo que permite evaluar la capacidad discriminativa del modelo. Posteriormente, se construye una rejilla de hiperparámetros que incluye diferentes combinaciones de parámetros. El objetivo de esta búsqueda es encontrar la configuración que maximiza el rendimiento predictivo del modelo evitando sobreajuste.

```{r message=FALSE, warning=FALSE}
pred_prob <- predict(xgb_model, newdata = test_x, type = "prob")[, "Si"]
pred_class <- ifelse(pred_prob > 0.5, "Si", "No")

plot_confusion <- function(actual, predicted, title = "Matriz de Confusión") {
  
  # Matriz de confusión
  cm <- confusionMatrix(factor(predicted), factor(actual))
  
  # Convertir a tabla para ggplot
  cm_table <- as.data.frame(cm$table)
  colnames(cm_table) <- c("Predicción", "Real", "Freq")
  
  ggplot(cm_table, aes(x = Real, y = Predicción, fill = Freq)) +
    geom_tile(color = "white") +
    geom_text(aes(label = Freq), size = 6, color = "black") +
    scale_fill_gradient(low = "#D6EAF8", high = "#1B4F72") +
    theme_minimal() +
    labs(title = title, fill = "Frecuencia") +
    theme(
      plot.title = element_text(face = "bold", size = 14),
      axis.title.x = element_text(face = "bold"),
      axis.title.y = element_text(face = "bold")
    )
}

plot_confusion(test$decision, factor(pred_class), "Resultados en Test Set")
```

En esta sección se evalúa el desempeño del modelo utilizando el conjunto de test. Primero, se generan probabilidades de pertenencia a la clase “Si” y luego se convierten en predicciones binarias aplicando un umbral de 0.5. Para interpretar los resultados, se construye una matriz de confusión que compara las predicciones con los valores reales. La función plot_confusion() transforma la matriz en un formato visual mediante ggplot2, donde los recuadros indican la cantidad de observaciones clasificadas en cada categoría y la intensidad del color refleja la frecuencia.

```{r message=FALSE, warning=FALSE}
roc_obj <- roc(test_y, pred_prob)

roc_df <- data.frame(
  specificity = roc_obj$specificities,
  sensitivity = roc_obj$sensitivities
)

ggplot(roc_df, aes(x = 1 - specificity, y = sensitivity)) +
  geom_line(size = 1.2, color = "#1c61b6") +
  geom_abline(linetype = "dashed", color = "gray50") +
  theme_minimal() +
  labs(title = paste("Curva ROC - XGBoost (AUC =", round(auc(roc_obj), 3), ")"),
       x = "1 - Especificidad",
       y = "Sensibilidad")
```

La curva ROC representa la capacidad del modelo para distinguir entre compradores que toman la decisión de compra ("Si") y aquellos que no ("No"). En el eje vertical se muestra la sensibilidad, mientras que en el eje horizontal se representa 1−especificidad. La línea diagonal punteada corresponde al desempeño de un clasificador aleatorio, por lo que cuanto más alejada esté la curva de esa diagonal y más cerca se encuentre de la esquina superior izquierda, mejor es el desempeño del modelo. El valor del AUC obtenido (AUC = 0.95) indica que el modelo presenta una capacidad predictiva buena, siendo capaz de discriminar entre ambas clases con un nivel de precisión considerable.

```{r message=FALSE, warning=FALSE}
importance <- xgb.importance(model = xgb_model$finalModel) %>%
  mutate(Feature = reorder(Feature, Gain))

ggplot(importance, aes(x = Feature, y = Gain)) +
  geom_col(fill = "#0072B2") +
  coord_flip() +
  theme_minimal() +
  labs(title = "Importancia de las Variables - XGBoost",
       x = "Variable",
       y = "Ganancia (Gain)")
```

El gráfico de importancia de variables muestra cuáles características aportan más a las decisiones del modelo. La métrica utilizada es Gain, que representa cuánto mejora la capacidad predictiva del modelo cada variable cuando se usa en los árboles. Las variables situadas en la parte superior del gráfico tienen una contribución mayor, por lo que influyen más en la predicción de la decisión de compra. En cambio, las variables con valores de ganancia menores aportan menos información y tienen un impacto reducido en el resultado final. Este análisis permite identificar que tanto la satisfacción como el ratio emi/salario son más relevantes para explicar el comportamiento de compra.

# 6. Interpretación de resultados

El análisis exploratorio inicial permitió identificar que el precio de la vivienda presenta una distribución fuertemente asimétrica hacia la derecha, lo que sugiere la presencia de propiedades de alto valor que elevan significativamente la media. Para abordar esta asimetría, se aplicó una transformación logarítmica al precio, consiguiendo una distribución más cercana a la normalidad y adecuada para los modelos posteriores. 

No obstante, aunque la prueba de Shapiro–Wilk indicó que la normalidad no se cumple estrictamente, el tamaño muestral elevado permite confiar en la robustez de los contrastes aplicados. Asimismo, el test de Levene mostró que no existen diferencias estadísticamente significativas en la varianza del precio entre países, lo que justificó el uso de un ANOVA clásico para comparar medias entre regiones.

En cuanto al modelo de regresión logística, los resultados muestran que la decisión de compra está influida principalmente por el precio de la propiedad, el país y el nivel de satisfacción del comprador. El coeficiente negativo y altamente significativo asociado a `log_price` indica que, a medida que el precio de la vivienda aumenta, disminuye la probabilidad de compra. Esto sugiere que, incluso en mercados con abundante financiación, el coste continúa siendo un factor determinante en la viabilidad de la adquisición. 

Por otro lado, el coeficiente positivo de `satisfaction_score` revela que la valoración subjetiva del inmueble tiene un peso importante en la decisión, lo que resalta el componente emocional y experiencial del proceso de compra. Además, el análisis por país evidenció que algunos mercados, como Brasil, India, Sudáfrica, Singapur, UAE y Estados Unidos, presentan menores probabilidades de compra, lo que puede estar relacionado con diferencias económicas, culturales o estructurales en los mercados inmobiliarios considerados.

El análisis de componentes principales (PCA) se utilizó para reducir la dimensionalidad del conjunto de datos y detectar patrones en las variables relacionadas con la propiedad, el comprador y la financiación. Los resultados mostraron que el primer componente principal (PC1) explica alrededor del 20% de la variabilidad total, mientras que las diez primeras componentes capturan aproximadamente entre el 70% y el 75% de la varianza.

Esto indica que, aunque la información está relativamente dispersa, existen combinaciones lineales de las variables que permiten sintetizar parte relevante del comportamiento del sistema. La visualización de los individuos en el espacio de las dos primeras componentes reveló algunas leves diferencias en la distribución de los datos según el país, lo cual sugiere patrones estructurales en los mercados inmobiliarios analizados.

# 7. Conclusiones

Los resultados obtenidos en el estudio permiten concluir que la decisión de compra de una vivienda no depende únicamente de factores económicos objetivos como el precio o las condiciones de financiación, sino también de variables subjetivas como la satisfacción percibida con el inmueble. Aunque el aumento del precio reduce significativamente la probabilidad de compra, un mayor nivel de satisfacción puede contrarrestar parcialmente este efecto, explicando por qué viviendas aparentemente comparables pueden obtener resultados de venta diferentes. Asimismo, la influencia significativa del país pone de manifiesto la heterogeneidad del mercado inmobiliario global, donde las decisiones y comportamientos financieros no pueden generalizarse entre regiones.

El PCA permitió sintetizar parte de la variabilidad presente en el conjunto de datos y sugirió la existencia de estructuras relacionadas tanto con el perfil financiero del comprador (variables que contribuyen principalmente a PC1) como con las características de la vivienda (variables que contribuyen principalmente a PC2). En conjunto, los análisis realizados refuerzan la importancia de integrar factores económicos, sociales y emocionales en la interpretación de comportamientos de compra dentro del sector inmobiliario.

# 8. Limitaciones

Este estudio presenta algunas limitaciones que deben considerarse al interpretar los resultados. En primer lugar, aunque el dataset es amplio, se conoce que estos datos han sido generados de manera sintética, lo que implica que las relaciones observadas pueden no reflejar con exactitud el comportamiento de un mercado inmobiliario real.

En segundo lugar, el modelo de regresión logística captura relaciones lineales entre las variables, pero la toma de decisiones en la compra de vivienda puede involucrar efectos no lineales y dinámicas que no han sido modeladas.

Finalmente, si bien el PCA ha permitido explorar patrones globales, su interpretación puede ser limitada y sería conveniente complementarlo con análisis adicionales como el clustering.

# 9. Bibliografía

[1] Kaggle (2025). Global House Purchase Decision Dataset. Obtenido de: https://www.kaggle.com

[2] OpenAI (2025). Asistencia en redacción y análisis de datos mediante ChatGPT. Herramienta empleada para la interpretación estadística, síntesis de resultados y redacción del informe.